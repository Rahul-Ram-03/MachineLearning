{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pH</th>\n",
       "      <th>Temprature</th>\n",
       "      <th>Taste</th>\n",
       "      <th>Odor</th>\n",
       "      <th>Fat</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.6</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.6</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>253</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>246</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.5</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.6</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pH  Temprature  Taste  Odor  Fat  Turbidity  Colour   Grade\n",
       "0  6.6          35      1     0    1          0     254    high\n",
       "1  6.6          36      0     1    0          1     253    high\n",
       "2  8.5          70      1     1    1          1     246     low\n",
       "3  9.5          34      1     1    0          1     255     low\n",
       "4  6.6          37      0     0    0          0     255  medium"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the data \n",
    "df = pd.read_csv(\"milknew.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of X and Type of y:(<class 'numpy.ndarray'>, <class 'numpy.ndarray'>)\n"
     ]
    }
   ],
   "source": [
    "#loading the targets and the input features\n",
    "# converting them to numpy arrays\n",
    "y = df['Grade'].values\n",
    "X = df.iloc[:,0:7].values\n",
    "\n",
    "print(f\"Type of X and Type of y:{type(X), type(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train and X_test:((847, 7), (212, 7))\n",
      "Shape of y_train and y_test:((847,), (212,))\n"
     ]
    }
   ],
   "source": [
    "#splitting the data set into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "print(f\"Shape of X_train and X_test:{X_train.shape, X_test.shape}\")\n",
    "\n",
    "print(f\"Shape of y_train and y_test:{y_train.shape, y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row of X_train and X_test:(array([  7.4,  65. ,   0. ,   0. ,   0. ,   0. , 255. ]), array([  6.7,  38. ,   1. ,   0. ,   1. ,   0. , 255. ]))\n",
      "First five elements of y_train and y_test:(array(['low', 'medium', 'high', 'medium', 'high'], dtype=object), array(['high', 'low', 'medium', 'medium', 'medium'], dtype=object))\n"
     ]
    }
   ],
   "source": [
    "print(f\"First row of X_train and X_test:{X_train[0], X_test[0]}\")\n",
    "\n",
    "print(f\"First five elements of y_train and y_test:{y_train[0:5], y_test[0:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoded outputs of y_train and y_test:(array([1, 2, 0, 2, 0]), array([0, 1, 2, 2, 2]))\n"
     ]
    }
   ],
   "source": [
    "#Label encoding y_test  and y_train\n",
    "\n",
    "y_train = LabelEncoder().fit_transform(y_train) \n",
    "y_test = LabelEncoder().fit_transform(y_test)\n",
    "\n",
    "print(f\"Label encoded outputs of y_train and y_test:{y_train[0:5], y_test[0:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row of X_train and X_test after feature scaling: (array([ 0.55707032,  2.04010539, -1.08507045, -0.8660254 , -1.41546674,\n",
      "       -0.96404614,  0.7261271 ]), array([-0.00426705, -0.65946559,  0.86721746, -0.90109146,  0.6723502 ,\n",
      "       -1.05830052,  0.76562929]))\n"
     ]
    }
   ],
   "source": [
    "#Scaling the input features of X_train and X_test\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)\n",
    "\n",
    "print(f\"First row of X_train and X_test after feature scaling: {X_train[0], X_test[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a neural network model to determine the quality of the milk\n",
    "#Linear activation outputs applied to softmax is more numerically stable\n",
    "#compared to softmax activation\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(30,activation=\"relu\"),\n",
    "        Dense(15,activation=\"relu\"),\n",
    "        Dense(7,activation=\"relu\"),\n",
    "        Dense(3,activation=\"linear\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "27/27 [==============================] - 1s 3ms/step - loss: 0.9410\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6809\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5193\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4142\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3287\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2638\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2048\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1610\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1352\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1215\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1141\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1071\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1022\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0897\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0898\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0813\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0796\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0759\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0808\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0676\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0680\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0557\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0558\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0500\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0453\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0445\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0423\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0389\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0333\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0318\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0314\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0278\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0229\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0216\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0251\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0201\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0193\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0118\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0110\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0092\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0091\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0080\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0083\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0060\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0070\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0059\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0056\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f9ae5ab4f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compiling the model with the appropriate loss function and fitting the training data\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer = tf.keras.optimizers.Adam(0.002),\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n",
      "0.02358490566037736\n"
     ]
    }
   ],
   "source": [
    "#here we obtain the predictions of the network\n",
    "\n",
    "prediction = tf.nn.softmax(model.predict(X_test)).numpy()\n",
    "c=0\n",
    "for i in range(len(prediction)):\n",
    "    if(np.argmax(prediction[i])!=y_test[i]):\n",
    "        #print(f\" target and prediction: {np.argmax(prediction[i]), y_test[i]}\")\n",
    "        c = c + 1\n",
    "print(c/len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 2ms/step\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "pred = tf.nn.softmax(model.predict(X_train)).numpy()\n",
    "\n",
    "c=0\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    if(np.argmax(pred[i])!=y_train[i]):\n",
    "        c += 1\n",
    "print(c/len(y_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "490884e7e377a2da9966ed37e82831f3fd1d200c4fab21381ab5fe8f244ef56c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
